{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data....\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "print(\"[INFO] loading data....\")\n",
    "\n",
    "dataset = load_iris()\n",
    "(trainX, testX, trainY, testY) = train_test_split(dataset.data, dataset.target, test_size = 0.25)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape = (4,), activation = \"sigmoid\"))\n",
    "model.add(Dense(3, activation = \"sigmoid\"))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network.....\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/250\n",
      "112/112 [==============================] - 1s 13ms/step - loss: 1.1355 - accuracy: 0.3571 - val_loss: 1.1157 - val_accuracy: 0.3158\n",
      "Epoch 2/250\n",
      "112/112 [==============================] - 0s 229us/step - loss: 1.1015 - accuracy: 0.3393 - val_loss: 1.1111 - val_accuracy: 0.3158\n",
      "Epoch 3/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 1.1045 - accuracy: 0.3393 - val_loss: 1.1198 - val_accuracy: 0.2632\n",
      "Epoch 4/250\n",
      "112/112 [==============================] - 0s 143us/step - loss: 1.1131 - accuracy: 0.3571 - val_loss: 1.1372 - val_accuracy: 0.2632\n",
      "Epoch 5/250\n",
      "112/112 [==============================] - 0s 134us/step - loss: 1.1081 - accuracy: 0.3214 - val_loss: 1.1028 - val_accuracy: 0.3158\n",
      "Epoch 6/250\n",
      "112/112 [==============================] - 0s 134us/step - loss: 1.1080 - accuracy: 0.2768 - val_loss: 1.0922 - val_accuracy: 0.2632\n",
      "Epoch 7/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 1.0939 - accuracy: 0.2768 - val_loss: 1.1125 - val_accuracy: 0.2632\n",
      "Epoch 8/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 1.0780 - accuracy: 0.3571 - val_loss: 1.0749 - val_accuracy: 0.2632\n",
      "Epoch 9/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 1.0626 - accuracy: 0.5357 - val_loss: 1.0404 - val_accuracy: 0.6842\n",
      "Epoch 10/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 1.0370 - accuracy: 0.5179 - val_loss: 1.0122 - val_accuracy: 0.8947\n",
      "Epoch 11/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.9784 - accuracy: 0.7589 - val_loss: 0.9678 - val_accuracy: 0.7632\n",
      "Epoch 12/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.9155 - accuracy: 0.6696 - val_loss: 0.8736 - val_accuracy: 0.8158\n",
      "Epoch 13/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.8176 - accuracy: 0.7232 - val_loss: 0.7850 - val_accuracy: 0.6053\n",
      "Epoch 14/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 0.6952 - accuracy: 0.7857 - val_loss: 0.6664 - val_accuracy: 0.6842\n",
      "Epoch 15/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.6079 - accuracy: 0.6875 - val_loss: 0.6021 - val_accuracy: 0.8421\n",
      "Epoch 16/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.5406 - accuracy: 0.9464 - val_loss: 0.5687 - val_accuracy: 0.9737\n",
      "Epoch 17/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.5005 - accuracy: 0.9643 - val_loss: 0.5269 - val_accuracy: 0.9474\n",
      "Epoch 18/250\n",
      "112/112 [==============================] - 0s 179us/step - loss: 0.4645 - accuracy: 0.9464 - val_loss: 0.4986 - val_accuracy: 0.9211\n",
      "Epoch 19/250\n",
      "112/112 [==============================] - 0s 179us/step - loss: 0.4543 - accuracy: 0.8571 - val_loss: 0.4714 - val_accuracy: 0.9474\n",
      "Epoch 20/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.4183 - accuracy: 0.9554 - val_loss: 0.4530 - val_accuracy: 0.9474\n",
      "Epoch 21/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.4024 - accuracy: 0.9464 - val_loss: 0.4363 - val_accuracy: 0.9737\n",
      "Epoch 22/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.3892 - accuracy: 0.9018 - val_loss: 0.4121 - val_accuracy: 0.9737\n",
      "Epoch 23/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 0.3676 - accuracy: 0.8929 - val_loss: 0.4860 - val_accuracy: 0.7895\n",
      "Epoch 24/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.4590 - accuracy: 0.7679 - val_loss: 0.4040 - val_accuracy: 0.9211\n",
      "Epoch 25/250\n",
      "112/112 [==============================] - 0s 188us/step - loss: 0.4065 - accuracy: 0.8304 - val_loss: 0.4387 - val_accuracy: 0.9211\n",
      "Epoch 26/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.3451 - accuracy: 0.9375 - val_loss: 0.3432 - val_accuracy: 0.9474\n",
      "Epoch 27/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 0.3123 - accuracy: 0.9375 - val_loss: 0.3184 - val_accuracy: 0.9211\n",
      "Epoch 28/250\n",
      "112/112 [==============================] - 0s 179us/step - loss: 0.2954 - accuracy: 0.9375 - val_loss: 0.3101 - val_accuracy: 0.9737\n",
      "Epoch 29/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.2754 - accuracy: 0.9375 - val_loss: 0.3734 - val_accuracy: 0.8684\n",
      "Epoch 30/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.2884 - accuracy: 0.9286 - val_loss: 0.3394 - val_accuracy: 0.8684\n",
      "Epoch 31/250\n",
      "112/112 [==============================] - 0s 152us/step - loss: 0.3311 - accuracy: 0.8661 - val_loss: 0.4994 - val_accuracy: 0.7632\n",
      "Epoch 32/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.2989 - accuracy: 0.8929 - val_loss: 0.3064 - val_accuracy: 0.8947\n",
      "Epoch 33/250\n",
      "112/112 [==============================] - 0s 179us/step - loss: 0.3302 - accuracy: 0.8929 - val_loss: 0.3282 - val_accuracy: 0.8421\n",
      "Epoch 34/250\n",
      "112/112 [==============================] - 0s 170us/step - loss: 0.2383 - accuracy: 0.9643 - val_loss: 0.2280 - val_accuracy: 0.9474\n",
      "Epoch 35/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.1969 - accuracy: 0.9554 - val_loss: 0.2226 - val_accuracy: 0.9211\n",
      "Epoch 36/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.1983 - accuracy: 0.9643 - val_loss: 0.1968 - val_accuracy: 0.9474\n",
      "Epoch 37/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.1707 - accuracy: 0.9911 - val_loss: 0.2075 - val_accuracy: 0.9211\n",
      "Epoch 38/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.2026 - accuracy: 0.9464 - val_loss: 0.3295 - val_accuracy: 0.8684\n",
      "Epoch 39/250\n",
      "112/112 [==============================] - 0s 161us/step - loss: 0.2216 - accuracy: 0.9554 - val_loss: 0.3444 - val_accuracy: 0.8684\n",
      "Epoch 40/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.2308 - accuracy: 0.8839 - val_loss: 0.1852 - val_accuracy: 0.9474\n",
      "Epoch 41/250\n",
      "112/112 [==============================] - 0s 304us/step - loss: 0.2479 - accuracy: 0.8839 - val_loss: 0.2000 - val_accuracy: 0.9211\n",
      "Epoch 42/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1926 - accuracy: 0.9286 - val_loss: 0.2976 - val_accuracy: 0.8684\n",
      "Epoch 43/250\n",
      "112/112 [==============================] - 0s 304us/step - loss: 0.1665 - accuracy: 0.9286 - val_loss: 0.1597 - val_accuracy: 0.9474\n",
      "Epoch 44/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1556 - accuracy: 0.9643 - val_loss: 0.1937 - val_accuracy: 0.9211\n",
      "Epoch 45/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1666 - accuracy: 0.9554 - val_loss: 0.1486 - val_accuracy: 0.9737\n",
      "Epoch 46/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1630 - accuracy: 0.9464 - val_loss: 0.1773 - val_accuracy: 0.9211\n",
      "Epoch 47/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.1257 - accuracy: 0.9732 - val_loss: 0.1420 - val_accuracy: 0.9474\n",
      "Epoch 48/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1404 - accuracy: 0.9464 - val_loss: 0.1568 - val_accuracy: 0.9474\n",
      "Epoch 49/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1400 - accuracy: 0.9554 - val_loss: 0.3940 - val_accuracy: 0.8158\n",
      "Epoch 50/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.3394 - accuracy: 0.8750 - val_loss: 0.2102 - val_accuracy: 0.9211\n",
      "Epoch 51/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.2583 - accuracy: 0.8839 - val_loss: 0.4281 - val_accuracy: 0.8421\n",
      "Epoch 52/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1818 - accuracy: 0.9375 - val_loss: 0.1513 - val_accuracy: 0.9474\n",
      "Epoch 53/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1929 - accuracy: 0.9286 - val_loss: 0.2109 - val_accuracy: 0.9211\n",
      "Epoch 54/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1318 - accuracy: 0.9643 - val_loss: 0.2346 - val_accuracy: 0.9211\n",
      "Epoch 55/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1505 - accuracy: 0.9464 - val_loss: 0.1308 - val_accuracy: 0.9474\n",
      "Epoch 56/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1014 - accuracy: 0.9732 - val_loss: 0.1620 - val_accuracy: 0.9474\n",
      "Epoch 57/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1289 - accuracy: 0.9464 - val_loss: 0.2529 - val_accuracy: 0.9211\n",
      "Epoch 58/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1368 - accuracy: 0.9554 - val_loss: 0.1450 - val_accuracy: 0.9474\n",
      "Epoch 59/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1524 - accuracy: 0.9643 - val_loss: 0.1756 - val_accuracy: 0.9211\n",
      "Epoch 60/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.1482 - accuracy: 0.9554 - val_loss: 0.2651 - val_accuracy: 0.9211\n",
      "Epoch 61/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1112 - accuracy: 0.9643 - val_loss: 0.1441 - val_accuracy: 0.9474\n",
      "Epoch 62/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0978 - accuracy: 0.9643 - val_loss: 0.1243 - val_accuracy: 0.9474\n",
      "Epoch 63/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.0946 - accuracy: 0.9821 - val_loss: 0.1355 - val_accuracy: 0.9474\n",
      "Epoch 64/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0913 - accuracy: 0.9821 - val_loss: 0.1233 - val_accuracy: 0.9474\n",
      "Epoch 65/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1157 - accuracy: 0.9554 - val_loss: 0.2481 - val_accuracy: 0.9211\n",
      "Epoch 66/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1463 - accuracy: 0.9732 - val_loss: 0.1755 - val_accuracy: 0.9211\n",
      "Epoch 67/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0802 - accuracy: 0.9911 - val_loss: 0.1551 - val_accuracy: 0.9474\n",
      "Epoch 68/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.0883 - accuracy: 0.9643 - val_loss: 0.1145 - val_accuracy: 0.9474\n",
      "Epoch 69/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0928 - accuracy: 0.9643 - val_loss: 0.1390 - val_accuracy: 0.9474\n",
      "Epoch 70/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0827 - accuracy: 0.9821 - val_loss: 0.1095 - val_accuracy: 0.9737\n",
      "Epoch 71/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0989 - accuracy: 0.9732 - val_loss: 0.1181 - val_accuracy: 0.9474\n",
      "Epoch 72/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0927 - accuracy: 0.9643 - val_loss: 0.4147 - val_accuracy: 0.8421\n",
      "Epoch 73/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.5521 - accuracy: 0.8304 - val_loss: 1.0531 - val_accuracy: 0.6842\n",
      "Epoch 74/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.5388 - accuracy: 0.8304 - val_loss: 0.2635 - val_accuracy: 0.9211\n",
      "Epoch 75/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.3632 - accuracy: 0.8750 - val_loss: 0.3762 - val_accuracy: 0.8158\n",
      "Epoch 76/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.4085 - accuracy: 0.7500 - val_loss: 0.4568 - val_accuracy: 0.7895\n",
      "Epoch 77/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.3788 - accuracy: 0.8125 - val_loss: 0.3940 - val_accuracy: 0.9474\n",
      "Epoch 78/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.2681 - accuracy: 0.9375 - val_loss: 0.2062 - val_accuracy: 0.9737\n",
      "Epoch 79/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1204 - accuracy: 0.9554 - val_loss: 0.1672 - val_accuracy: 0.9474\n",
      "Epoch 80/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1471 - accuracy: 0.9375 - val_loss: 0.1172 - val_accuracy: 0.9474\n",
      "Epoch 81/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1005 - accuracy: 0.9732 - val_loss: 0.1107 - val_accuracy: 0.9474\n",
      "Epoch 82/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.1659 - accuracy: 0.9286 - val_loss: 0.1473 - val_accuracy: 0.9474\n",
      "Epoch 83/250\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.00 - 0s 250us/step - loss: 0.0724 - accuracy: 0.9911 - val_loss: 0.1236 - val_accuracy: 0.9474\n",
      "Epoch 84/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.0889 - accuracy: 0.9821 - val_loss: 0.1482 - val_accuracy: 0.9474\n",
      "Epoch 85/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0795 - accuracy: 0.9732 - val_loss: 0.1143 - val_accuracy: 0.9474\n",
      "Epoch 86/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0730 - accuracy: 0.9821 - val_loss: 0.1684 - val_accuracy: 0.9474\n",
      "Epoch 87/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0985 - accuracy: 0.9554 - val_loss: 0.1110 - val_accuracy: 0.9737\n",
      "Epoch 88/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1266 - accuracy: 0.9554 - val_loss: 0.2549 - val_accuracy: 0.9211\n",
      "Epoch 89/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1138 - accuracy: 0.9554 - val_loss: 0.1646 - val_accuracy: 0.9474\n",
      "Epoch 90/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1894 - accuracy: 0.9286 - val_loss: 0.1280 - val_accuracy: 0.9474\n",
      "Epoch 91/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.4295 - accuracy: 0.8393 - val_loss: 0.1989 - val_accuracy: 0.9211\n",
      "Epoch 92/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1750 - accuracy: 0.9375 - val_loss: 0.2296 - val_accuracy: 0.9211\n",
      "Epoch 93/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1455 - accuracy: 0.9732 - val_loss: 0.1774 - val_accuracy: 0.9474\n",
      "Epoch 94/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0933 - accuracy: 0.9732 - val_loss: 0.1599 - val_accuracy: 0.9474\n",
      "Epoch 95/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 0.1336 - val_accuracy: 0.9474\n",
      "Epoch 96/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0870 - accuracy: 0.9732 - val_loss: 0.1470 - val_accuracy: 0.9474\n",
      "Epoch 97/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0828 - accuracy: 0.9821 - val_loss: 0.1067 - val_accuracy: 0.9737\n",
      "Epoch 98/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1351 - accuracy: 0.9554 - val_loss: 0.1268 - val_accuracy: 0.9474\n",
      "Epoch 99/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0848 - accuracy: 0.9732 - val_loss: 0.1318 - val_accuracy: 0.9474\n",
      "Epoch 100/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0930 - accuracy: 0.9643 - val_loss: 0.1490 - val_accuracy: 0.9474\n",
      "Epoch 101/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1052 - accuracy: 0.9554 - val_loss: 0.4426 - val_accuracy: 0.8158\n",
      "Epoch 102/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.2947 - accuracy: 0.8750 - val_loss: 0.2784 - val_accuracy: 0.9211\n",
      "Epoch 103/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1679 - accuracy: 0.9286 - val_loss: 0.1978 - val_accuracy: 0.9211\n",
      "Epoch 104/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0812 - accuracy: 0.9911 - val_loss: 0.1515 - val_accuracy: 0.9474\n",
      "Epoch 105/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1878 - accuracy: 0.9286 - val_loss: 0.2871 - val_accuracy: 0.8947\n",
      "Epoch 106/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1383 - accuracy: 0.9375 - val_loss: 0.1386 - val_accuracy: 0.9474\n",
      "Epoch 107/250\n",
      "112/112 [==============================] - 0s 232us/step - loss: 0.1305 - accuracy: 0.9554 - val_loss: 0.1635 - val_accuracy: 0.9474\n",
      "Epoch 108/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1854 - accuracy: 0.9464 - val_loss: 0.1477 - val_accuracy: 0.9474\n",
      "Epoch 109/250\n",
      "112/112 [==============================] - 0s 232us/step - loss: 0.0841 - accuracy: 0.9643 - val_loss: 0.1178 - val_accuracy: 0.9474\n",
      "Epoch 110/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0760 - accuracy: 0.9732 - val_loss: 0.1253 - val_accuracy: 0.9474\n",
      "Epoch 111/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0784 - accuracy: 0.9732 - val_loss: 0.1204 - val_accuracy: 0.9211\n",
      "Epoch 112/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0981 - accuracy: 0.9643 - val_loss: 0.1711 - val_accuracy: 0.9474\n",
      "Epoch 113/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0844 - accuracy: 0.9732 - val_loss: 0.2227 - val_accuracy: 0.9211\n",
      "Epoch 114/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0679 - accuracy: 0.9732 - val_loss: 0.1595 - val_accuracy: 0.9474\n",
      "Epoch 115/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0694 - accuracy: 0.9821 - val_loss: 0.2546 - val_accuracy: 0.9211\n",
      "Epoch 116/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.1208 - accuracy: 0.9554 - val_loss: 0.1918 - val_accuracy: 0.9211\n",
      "Epoch 117/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.0892 - accuracy: 0.9643 - val_loss: 0.1134 - val_accuracy: 0.9474\n",
      "Epoch 118/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1149 - accuracy: 0.9643 - val_loss: 0.1592 - val_accuracy: 0.9474\n",
      "Epoch 119/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.1090 - val_accuracy: 0.9474\n",
      "Epoch 120/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0634 - accuracy: 0.9911 - val_loss: 0.1417 - val_accuracy: 0.9474\n",
      "Epoch 121/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0905 - accuracy: 0.9643 - val_loss: 0.1516 - val_accuracy: 0.9474\n",
      "Epoch 122/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0758 - accuracy: 0.9732 - val_loss: 0.1080 - val_accuracy: 0.9474\n",
      "Epoch 123/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0873 - accuracy: 0.9732 - val_loss: 0.1665 - val_accuracy: 0.9474\n",
      "Epoch 124/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0683 - accuracy: 0.9911 - val_loss: 0.1097 - val_accuracy: 0.9474\n",
      "Epoch 125/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0898 - accuracy: 0.9554 - val_loss: 0.1750 - val_accuracy: 0.9474\n",
      "Epoch 126/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0950 - accuracy: 0.9732 - val_loss: 0.1501 - val_accuracy: 0.9474\n",
      "Epoch 127/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0587 - accuracy: 0.9911 - val_loss: 0.2023 - val_accuracy: 0.9211\n",
      "Epoch 128/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0802 - accuracy: 0.9821 - val_loss: 0.1418 - val_accuracy: 0.9211\n",
      "Epoch 129/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0817 - accuracy: 0.9821 - val_loss: 0.1712 - val_accuracy: 0.9474\n",
      "Epoch 130/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1069 - accuracy: 0.9732 - val_loss: 0.1193 - val_accuracy: 0.9474\n",
      "Epoch 131/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0990 - accuracy: 0.9732 - val_loss: 0.1175 - val_accuracy: 0.9474\n",
      "Epoch 132/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0736 - accuracy: 0.9732 - val_loss: 0.1850 - val_accuracy: 0.9211\n",
      "Epoch 133/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0766 - accuracy: 0.9821 - val_loss: 0.1601 - val_accuracy: 0.9474\n",
      "Epoch 134/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0904 - accuracy: 0.9732 - val_loss: 0.1782 - val_accuracy: 0.9474\n",
      "Epoch 135/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.1053 - accuracy: 0.9554 - val_loss: 0.1151 - val_accuracy: 0.9737\n",
      "Epoch 136/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0603 - accuracy: 0.9911 - val_loss: 0.1380 - val_accuracy: 0.9474\n",
      "Epoch 137/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.1158 - val_accuracy: 0.9474\n",
      "Epoch 138/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0735 - accuracy: 0.9732 - val_loss: 0.1378 - val_accuracy: 0.9474\n",
      "Epoch 139/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0653 - accuracy: 0.9821 - val_loss: 0.1284 - val_accuracy: 0.9474\n",
      "Epoch 140/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0937 - accuracy: 0.9732 - val_loss: 0.1532 - val_accuracy: 0.9474\n",
      "Epoch 141/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0685 - accuracy: 0.9821 - val_loss: 0.1227 - val_accuracy: 0.9474\n",
      "Epoch 142/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0651 - accuracy: 0.9732 - val_loss: 0.1201 - val_accuracy: 0.9474\n",
      "Epoch 143/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0624 - accuracy: 0.9821 - val_loss: 0.1263 - val_accuracy: 0.9474\n",
      "Epoch 144/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0683 - accuracy: 0.9821 - val_loss: 0.1759 - val_accuracy: 0.9474\n",
      "Epoch 145/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0877 - accuracy: 0.9732 - val_loss: 0.1392 - val_accuracy: 0.9211\n",
      "Epoch 146/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1130 - accuracy: 0.9643 - val_loss: 0.1244 - val_accuracy: 0.9474\n",
      "Epoch 147/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0776 - accuracy: 0.9732 - val_loss: 0.1439 - val_accuracy: 0.9474\n",
      "Epoch 148/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1220 - accuracy: 0.9554 - val_loss: 0.1582 - val_accuracy: 0.9211\n",
      "Epoch 149/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1225 - accuracy: 0.9643 - val_loss: 0.1651 - val_accuracy: 0.9474\n",
      "Epoch 150/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1041 - accuracy: 0.9643 - val_loss: 0.1274 - val_accuracy: 0.9474\n",
      "Epoch 151/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1467 - accuracy: 0.9554 - val_loss: 0.3299 - val_accuracy: 0.8947\n",
      "Epoch 152/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.3780 - accuracy: 0.8393 - val_loss: 0.4339 - val_accuracy: 0.8947\n",
      "Epoch 153/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.4406 - accuracy: 0.9018 - val_loss: 0.2068 - val_accuracy: 0.9211\n",
      "Epoch 154/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.2878 - accuracy: 0.8571 - val_loss: 0.2104 - val_accuracy: 0.9211\n",
      "Epoch 155/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1768 - accuracy: 0.9554 - val_loss: 0.2368 - val_accuracy: 0.9211\n",
      "Epoch 156/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1009 - accuracy: 0.9732 - val_loss: 0.1824 - val_accuracy: 0.9211\n",
      "Epoch 157/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0793 - accuracy: 0.9732 - val_loss: 0.1380 - val_accuracy: 0.9211\n",
      "Epoch 158/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0685 - accuracy: 0.9821 - val_loss: 0.2041 - val_accuracy: 0.9211\n",
      "Epoch 159/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0837 - accuracy: 0.9732 - val_loss: 0.1388 - val_accuracy: 0.9211\n",
      "Epoch 160/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0723 - accuracy: 0.9821 - val_loss: 0.1290 - val_accuracy: 0.9474\n",
      "Epoch 161/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0624 - accuracy: 0.9911 - val_loss: 0.1274 - val_accuracy: 0.9474\n",
      "Epoch 162/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.1276 - val_accuracy: 0.9211\n",
      "Epoch 163/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0737 - accuracy: 0.9732 - val_loss: 0.1674 - val_accuracy: 0.9474\n",
      "Epoch 164/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0677 - accuracy: 0.9821 - val_loss: 0.1394 - val_accuracy: 0.9211\n",
      "Epoch 165/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1003 - accuracy: 0.9732 - val_loss: 0.1682 - val_accuracy: 0.9474\n",
      "Epoch 166/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0690 - accuracy: 0.9821 - val_loss: 0.1542 - val_accuracy: 0.9211\n",
      "Epoch 167/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0848 - accuracy: 0.9554 - val_loss: 0.1508 - val_accuracy: 0.9474\n",
      "Epoch 168/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0686 - accuracy: 0.9911 - val_loss: 0.1174 - val_accuracy: 0.9737\n",
      "Epoch 169/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0993 - accuracy: 0.9732 - val_loss: 0.1521 - val_accuracy: 0.9474\n",
      "Epoch 170/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1168 - accuracy: 0.9732 - val_loss: 0.1198 - val_accuracy: 0.9474\n",
      "Epoch 171/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0692 - accuracy: 0.9821 - val_loss: 0.1375 - val_accuracy: 0.9474\n",
      "Epoch 172/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0697 - accuracy: 0.9821 - val_loss: 0.1519 - val_accuracy: 0.9474\n",
      "Epoch 173/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0671 - accuracy: 0.9821 - val_loss: 0.1184 - val_accuracy: 0.9474\n",
      "Epoch 174/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0725 - accuracy: 0.9732 - val_loss: 0.1723 - val_accuracy: 0.9474\n",
      "Epoch 175/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1553 - accuracy: 0.9464 - val_loss: 0.1231 - val_accuracy: 0.9474\n",
      "Epoch 176/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0748 - accuracy: 0.9732 - val_loss: 0.1204 - val_accuracy: 0.9474\n",
      "Epoch 177/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0543 - accuracy: 0.9911 - val_loss: 0.1748 - val_accuracy: 0.9474\n",
      "Epoch 178/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0833 - accuracy: 0.9732 - val_loss: 0.1833 - val_accuracy: 0.9211\n",
      "Epoch 179/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.1465 - accuracy: 0.9554 - val_loss: 0.1594 - val_accuracy: 0.9474\n",
      "Epoch 180/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1240 - accuracy: 0.9464 - val_loss: 0.1171 - val_accuracy: 0.9474\n",
      "Epoch 181/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1892 - accuracy: 0.9464 - val_loss: 0.1903 - val_accuracy: 0.9474\n",
      "Epoch 182/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1074 - accuracy: 0.9732 - val_loss: 0.1745 - val_accuracy: 0.9211\n",
      "Epoch 183/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1269 - accuracy: 0.9554 - val_loss: 0.1855 - val_accuracy: 0.9474\n",
      "Epoch 184/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0641 - accuracy: 0.9911 - val_loss: 0.1178 - val_accuracy: 0.9474\n",
      "Epoch 185/250\n",
      "112/112 [==============================] - 0s 304us/step - loss: 0.0853 - accuracy: 0.9732 - val_loss: 0.1409 - val_accuracy: 0.9474\n",
      "Epoch 186/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0834 - accuracy: 0.9732 - val_loss: 0.1181 - val_accuracy: 0.9474\n",
      "Epoch 187/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0766 - accuracy: 0.9821 - val_loss: 0.1438 - val_accuracy: 0.9474\n",
      "Epoch 188/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0639 - accuracy: 0.9821 - val_loss: 0.1189 - val_accuracy: 0.9737\n",
      "Epoch 189/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0794 - accuracy: 0.9643 - val_loss: 0.1352 - val_accuracy: 0.9474\n",
      "Epoch 190/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0906 - accuracy: 0.9643 - val_loss: 0.2008 - val_accuracy: 0.9211\n",
      "Epoch 191/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0961 - accuracy: 0.9732 - val_loss: 0.1293 - val_accuracy: 0.9474\n",
      "Epoch 192/250\n",
      "112/112 [==============================] - 0s 232us/step - loss: 0.0626 - accuracy: 0.9911 - val_loss: 0.1227 - val_accuracy: 0.9474\n",
      "Epoch 193/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0639 - accuracy: 0.9732 - val_loss: 0.1591 - val_accuracy: 0.9474\n",
      "Epoch 194/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0885 - accuracy: 0.9643 - val_loss: 0.2186 - val_accuracy: 0.9211\n",
      "Epoch 195/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0848 - accuracy: 0.9821 - val_loss: 0.2392 - val_accuracy: 0.9211\n",
      "Epoch 196/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0970 - accuracy: 0.9732 - val_loss: 0.1539 - val_accuracy: 0.9211\n",
      "Epoch 197/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0743 - accuracy: 0.9821 - val_loss: 0.1363 - val_accuracy: 0.9474\n",
      "Epoch 198/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0724 - accuracy: 0.9732 - val_loss: 0.1209 - val_accuracy: 0.9474\n",
      "Epoch 199/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0794 - accuracy: 0.9643 - val_loss: 0.2118 - val_accuracy: 0.9211\n",
      "Epoch 200/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.1351 - accuracy: 0.9464 - val_loss: 0.1541 - val_accuracy: 0.9474\n",
      "Epoch 201/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1948 - accuracy: 0.9375 - val_loss: 0.1219 - val_accuracy: 0.9474\n",
      "Epoch 202/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1165 - accuracy: 0.9643 - val_loss: 0.2309 - val_accuracy: 0.9211\n",
      "Epoch 203/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.1164 - accuracy: 0.9643 - val_loss: 0.1271 - val_accuracy: 0.9474\n",
      "Epoch 204/250\n",
      "112/112 [==============================] - 0s 232us/step - loss: 0.0830 - accuracy: 0.9732 - val_loss: 0.2116 - val_accuracy: 0.9211\n",
      "Epoch 205/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0828 - accuracy: 0.9732 - val_loss: 0.1773 - val_accuracy: 0.9474\n",
      "Epoch 206/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0906 - accuracy: 0.9732 - val_loss: 0.1517 - val_accuracy: 0.9474\n",
      "Epoch 207/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0835 - accuracy: 0.9732 - val_loss: 0.1397 - val_accuracy: 0.9474\n",
      "Epoch 208/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0815 - accuracy: 0.9821 - val_loss: 0.1265 - val_accuracy: 0.9474\n",
      "Epoch 209/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0543 - accuracy: 0.9911 - val_loss: 0.1646 - val_accuracy: 0.9474\n",
      "Epoch 210/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0580 - accuracy: 0.9821 - val_loss: 0.1203 - val_accuracy: 0.9474\n",
      "Epoch 211/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.1279 - val_accuracy: 0.9474\n",
      "Epoch 212/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0572 - accuracy: 0.9911 - val_loss: 0.1253 - val_accuracy: 0.9474\n",
      "Epoch 213/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0610 - accuracy: 0.9821 - val_loss: 0.1254 - val_accuracy: 0.9474\n",
      "Epoch 214/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0607 - accuracy: 0.9821 - val_loss: 0.1365 - val_accuracy: 0.9474\n",
      "Epoch 215/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0642 - accuracy: 0.9732 - val_loss: 0.1300 - val_accuracy: 0.9474\n",
      "Epoch 216/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.1417 - val_accuracy: 0.9474\n",
      "Epoch 217/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.1268 - val_accuracy: 0.9474\n",
      "Epoch 218/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0684 - accuracy: 0.9732 - val_loss: 0.1581 - val_accuracy: 0.9474\n",
      "Epoch 219/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0636 - accuracy: 0.9821 - val_loss: 0.1303 - val_accuracy: 0.9474\n",
      "Epoch 220/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0681 - accuracy: 0.9732 - val_loss: 0.1330 - val_accuracy: 0.9474\n",
      "Epoch 221/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1177 - accuracy: 0.9464 - val_loss: 0.2030 - val_accuracy: 0.9211\n",
      "Epoch 222/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.1324 - accuracy: 0.9464 - val_loss: 0.1571 - val_accuracy: 0.9474\n",
      "Epoch 223/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0736 - accuracy: 0.9821 - val_loss: 0.1188 - val_accuracy: 0.9474\n",
      "Epoch 224/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0566 - accuracy: 0.9911 - val_loss: 0.1386 - val_accuracy: 0.9474\n",
      "Epoch 225/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0599 - accuracy: 0.9911 - val_loss: 0.1203 - val_accuracy: 0.9474\n",
      "Epoch 226/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0852 - accuracy: 0.9643 - val_loss: 0.1552 - val_accuracy: 0.9474\n",
      "Epoch 227/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0776 - accuracy: 0.9732 - val_loss: 0.1179 - val_accuracy: 0.9474\n",
      "Epoch 228/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0866 - accuracy: 0.9732 - val_loss: 0.1593 - val_accuracy: 0.9474\n",
      "Epoch 229/250\n",
      "112/112 [==============================] - 0s 232us/step - loss: 0.0845 - accuracy: 0.9821 - val_loss: 0.1197 - val_accuracy: 0.9474\n",
      "Epoch 230/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0861 - accuracy: 0.9732 - val_loss: 0.1736 - val_accuracy: 0.9474\n",
      "Epoch 231/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0561 - accuracy: 0.9911 - val_loss: 0.1526 - val_accuracy: 0.9211\n",
      "Epoch 232/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0657 - accuracy: 0.9821 - val_loss: 0.1470 - val_accuracy: 0.9474\n",
      "Epoch 233/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.0653 - accuracy: 0.9732 - val_loss: 0.1258 - val_accuracy: 0.9474\n",
      "Epoch 234/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0542 - accuracy: 0.9911 - val_loss: 0.1303 - val_accuracy: 0.9474\n",
      "Epoch 235/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0571 - accuracy: 0.9821 - val_loss: 0.1303 - val_accuracy: 0.9474\n",
      "Epoch 236/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0594 - accuracy: 0.9821 - val_loss: 0.1193 - val_accuracy: 0.9737\n",
      "Epoch 237/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0770 - accuracy: 0.9821 - val_loss: 0.1222 - val_accuracy: 0.9474\n",
      "Epoch 238/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0891 - accuracy: 0.9732 - val_loss: 0.1591 - val_accuracy: 0.9474\n",
      "Epoch 239/250\n",
      "112/112 [==============================] - 0s 268us/step - loss: 0.0843 - accuracy: 0.9732 - val_loss: 0.1232 - val_accuracy: 0.9474\n",
      "Epoch 240/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.1652 - val_accuracy: 0.9474\n",
      "Epoch 241/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0943 - accuracy: 0.9643 - val_loss: 0.1486 - val_accuracy: 0.9474\n",
      "Epoch 242/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0961 - accuracy: 0.9732 - val_loss: 0.1822 - val_accuracy: 0.9474\n",
      "Epoch 243/250\n",
      "112/112 [==============================] - 0s 313us/step - loss: 0.1022 - accuracy: 0.9554 - val_loss: 0.1506 - val_accuracy: 0.9474\n",
      "Epoch 244/250\n",
      "112/112 [==============================] - 0s 241us/step - loss: 0.1394 - accuracy: 0.9554 - val_loss: 0.1591 - val_accuracy: 0.9474\n",
      "Epoch 245/250\n",
      "112/112 [==============================] - 0s 286us/step - loss: 0.1416 - accuracy: 0.9554 - val_loss: 0.1583 - val_accuracy: 0.9474\n",
      "Epoch 246/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.1067 - accuracy: 0.9643 - val_loss: 0.1473 - val_accuracy: 0.9474\n",
      "Epoch 247/250\n",
      "112/112 [==============================] - 0s 277us/step - loss: 0.0905 - accuracy: 0.9821 - val_loss: 0.1219 - val_accuracy: 0.9474\n",
      "Epoch 248/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0574 - accuracy: 0.9911 - val_loss: 0.1900 - val_accuracy: 0.9211\n",
      "Epoch 249/250\n",
      "112/112 [==============================] - 0s 259us/step - loss: 0.0822 - accuracy: 0.9732 - val_loss: 0.1211 - val_accuracy: 0.9474\n",
      "Epoch 250/250\n",
      "112/112 [==============================] - 0s 250us/step - loss: 0.0622 - accuracy: 0.9821 - val_loss: 0.1196 - val_accuracy: 0.9474\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.92      0.92      0.92        12\n",
      "   virginica       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.95      0.95      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"[INFO] training network.....\")\n",
    "opt = SGD(lr = 0.1, momentum = 0.9, decay = 0.1 / 250)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX,testY), epochs=250, batch_size=16)\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=16)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
